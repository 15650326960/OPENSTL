Model info:
SimVP_Model(
  (enc): Encoder(
    (enc): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
    )
  )
  (dec): Decoder(
    (dec): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Sequential(
            (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
    )
    (readout): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (hid): MidMetaNet(
    (enc): Sequential(
      (0): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
              (conv_spatial): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=384)
              (conv1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=384, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=384, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.010)
          (norm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(3072, 384, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
              (conv_spatial): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=256)
              (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=256, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=256, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.023)
          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (2): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
              (conv_spatial): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=256)
              (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=256, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=256, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.036)
          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (3): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
              (conv_spatial): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=256)
              (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=256, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=256, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.049)
          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (4): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
              (conv_spatial): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=256)
              (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=256, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=256, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.061)
          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (5): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
              (conv_spatial): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=256)
              (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=256, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=256, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.074)
          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (6): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
              (conv_spatial): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=256)
              (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=256, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=256, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.087)
          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (7): MetaBlock(
        (block): TAUSubBlock(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): TemporalAttention(
            (proj_1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): TemporalAttentionModule(
              (conv0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
              (conv_spatial): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=256)
              (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (fc): Sequential(
                (0): Linear(in_features=256, out_features=16, bias=False)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=16, out_features=256, bias=False)
                (3): Sigmoid()
              )
            )
            (proj_2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.100)
          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
| module                           | #parameters or shape   | #flops     |
|:---------------------------------|:-----------------------|:-----------|
| model                            | 12.22M                 | 6.703G     |
|  enc.enc                         |  9.696K                |  68.616M   |
|   enc.enc.0.conv                 |   0.384K               |   11.01M   |
|    enc.enc.0.conv.conv           |    0.32K               |    7.078M  |
|    enc.enc.0.conv.norm           |    64                  |    3.932M  |
|   enc.enc.1.conv                 |   9.312K               |   57.606M  |
|    enc.enc.1.conv.conv           |    9.248K              |    56.623M |
|    enc.enc.1.conv.norm           |    64                  |    0.983M  |
|  dec                             |  46.401K               |  0.462G    |
|   dec.dec                        |   46.368K              |   0.461G   |
|    dec.dec.0.conv                |    37.056K             |    0.23G   |
|    dec.dec.1.conv                |    9.312K              |    0.23G   |
|   dec.readout                    |   33                   |   0.786M   |
|    dec.readout.weight            |    (1, 32, 1, 1)       |            |
|    dec.readout.bias              |    (1,)                |            |
|  hid.enc                         |  12.163M               |  6.173G    |
|   hid.enc.0                      |   2.979M               |   1.516G   |
|    hid.enc.0.block               |    2.881M              |    1.465G  |
|    hid.enc.0.reduction           |    98.56K              |    50.332M |
|   hid.enc.1.block                |   1.298M               |   0.658G   |
|    hid.enc.1.block.layer_scale_1 |    (256,)              |            |
|    hid.enc.1.block.layer_scale_2 |    (256,)              |            |
|    hid.enc.1.block.norm1         |    0.512K              |    0.655M  |
|    hid.enc.1.block.attn          |    0.225M              |    0.111G  |
|    hid.enc.1.block.norm2         |    0.512K              |    0.655M  |
|    hid.enc.1.block.mlp           |    1.071M              |    0.546G  |
|   hid.enc.2.block                |   1.298M               |   0.658G   |
|    hid.enc.2.block.layer_scale_1 |    (256,)              |            |
|    hid.enc.2.block.layer_scale_2 |    (256,)              |            |
|    hid.enc.2.block.norm1         |    0.512K              |    0.655M  |
|    hid.enc.2.block.attn          |    0.225M              |    0.111G  |
|    hid.enc.2.block.norm2         |    0.512K              |    0.655M  |
|    hid.enc.2.block.mlp           |    1.071M              |    0.546G  |
|   hid.enc.3.block                |   1.298M               |   0.658G   |
|    hid.enc.3.block.layer_scale_1 |    (256,)              |            |
|    hid.enc.3.block.layer_scale_2 |    (256,)              |            |
|    hid.enc.3.block.norm1         |    0.512K              |    0.655M  |
|    hid.enc.3.block.attn          |    0.225M              |    0.111G  |
|    hid.enc.3.block.norm2         |    0.512K              |    0.655M  |
|    hid.enc.3.block.mlp           |    1.071M              |    0.546G  |
|   hid.enc.4.block                |   1.298M               |   0.658G   |
|    hid.enc.4.block.layer_scale_1 |    (256,)              |            |
|    hid.enc.4.block.layer_scale_2 |    (256,)              |            |
|    hid.enc.4.block.norm1         |    0.512K              |    0.655M  |
|    hid.enc.4.block.attn          |    0.225M              |    0.111G  |
|    hid.enc.4.block.norm2         |    0.512K              |    0.655M  |
|    hid.enc.4.block.mlp           |    1.071M              |    0.546G  |
|   hid.enc.5.block                |   1.298M               |   0.658G   |
|    hid.enc.5.block.layer_scale_1 |    (256,)              |            |
|    hid.enc.5.block.layer_scale_2 |    (256,)              |            |
|    hid.enc.5.block.norm1         |    0.512K              |    0.655M  |
|    hid.enc.5.block.attn          |    0.225M              |    0.111G  |
|    hid.enc.5.block.norm2         |    0.512K              |    0.655M  |
|    hid.enc.5.block.mlp           |    1.071M              |    0.546G  |
|   hid.enc.6.block                |   1.298M               |   0.658G   |
|    hid.enc.6.block.layer_scale_1 |    (256,)              |            |
|    hid.enc.6.block.layer_scale_2 |    (256,)              |            |
|    hid.enc.6.block.norm1         |    0.512K              |    0.655M  |
|    hid.enc.6.block.attn          |    0.225M              |    0.111G  |
|    hid.enc.6.block.norm2         |    0.512K              |    0.655M  |
|    hid.enc.6.block.mlp           |    1.071M              |    0.546G  |
|   hid.enc.7                      |   1.397M               |   0.708G   |
|    hid.enc.7.block               |    1.298M              |    0.658G  |
|    hid.enc.7.reduction           |    98.688K             |    50.332M |
--------------------------------------------------------------------------------
1726054618918 tiger error 
  | Name      | Type        | Params
------------------------------------------
0 | model     | SimVP_Model | 12.2 M
1 | criterion | MSELoss     | 0     
------------------------------------------
12.2 M    Trainable params
0         Non-trainable params
12.2 M    Total params
48.878    Total estimated model params size (MB)
