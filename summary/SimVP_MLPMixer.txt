Model info:
SimVP_Model(
  (enc): Encoder(
    (enc): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
    )
  )
  (dec): Decoder(
    (dec): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Sequential(
            (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 32, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
    )
    (readout): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (hid): MidMetaNet(
    (enc): Sequential(
      (0): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=192, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=192, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.010)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=384, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=3072, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=128, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=128, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.023)
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (2): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=128, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=128, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.036)
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (3): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=128, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=128, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.049)
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (4): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=128, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=128, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.061)
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (5): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=128, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=128, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.074)
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (6): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=128, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=128, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.087)
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (7): MetaBlock(
        (block): MLPMixerSubBlock(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_tokens): Mlp(
            (fc1): Linear(in_features=512, out_features=128, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=128, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.100)
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp_channels): Mlp(
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
| module                          | #parameters or shape   | #flops     |
|:--------------------------------|:-----------------------|:-----------|
| model                           | 11.1M                  | 5.918G     |
|  enc.enc                        |  9.696K                |  68.616M   |
|   enc.enc.0.conv                |   0.384K               |   11.01M   |
|    enc.enc.0.conv.conv          |    0.32K               |    7.078M  |
|    enc.enc.0.conv.norm          |    64                  |    3.932M  |
|   enc.enc.1.conv                |   9.312K               |   57.606M  |
|    enc.enc.1.conv.conv          |    9.248K              |    56.623M |
|    enc.enc.1.conv.norm          |    64                  |    0.983M  |
|  dec                            |  46.401K               |  0.462G    |
|   dec.dec                       |   46.368K              |   0.461G   |
|    dec.dec.0.conv               |    37.056K             |    0.23G   |
|    dec.dec.1.conv               |    9.312K              |    0.23G   |
|   dec.readout                   |   33                   |   0.786M   |
|    dec.readout.weight           |    (1, 32, 1, 1)       |            |
|    dec.readout.bias             |    (1,)                |            |
|  hid.enc                        |  11.044M               |  5.388G    |
|   hid.enc.0                     |   2.66M                |   1.336G   |
|    hid.enc.0.block              |    2.562M              |    1.285G  |
|    hid.enc.0.reduction          |    98.56K              |    50.332M |
|   hid.enc.1.block               |   1.184M               |   0.572G   |
|    hid.enc.1.block.norm1        |    0.512K              |    0.655M  |
|    hid.enc.1.block.mlp_tokens   |    0.132M              |    33.554M |
|    hid.enc.1.block.norm2        |    0.512K              |    0.655M  |
|    hid.enc.1.block.mlp_channels |    1.051M              |    0.537G  |
|   hid.enc.2.block               |   1.184M               |   0.572G   |
|    hid.enc.2.block.norm1        |    0.512K              |    0.655M  |
|    hid.enc.2.block.mlp_tokens   |    0.132M              |    33.554M |
|    hid.enc.2.block.norm2        |    0.512K              |    0.655M  |
|    hid.enc.2.block.mlp_channels |    1.051M              |    0.537G  |
|   hid.enc.3.block               |   1.184M               |   0.572G   |
|    hid.enc.3.block.norm1        |    0.512K              |    0.655M  |
|    hid.enc.3.block.mlp_tokens   |    0.132M              |    33.554M |
|    hid.enc.3.block.norm2        |    0.512K              |    0.655M  |
|    hid.enc.3.block.mlp_channels |    1.051M              |    0.537G  |
|   hid.enc.4.block               |   1.184M               |   0.572G   |
|    hid.enc.4.block.norm1        |    0.512K              |    0.655M  |
|    hid.enc.4.block.mlp_tokens   |    0.132M              |    33.554M |
|    hid.enc.4.block.norm2        |    0.512K              |    0.655M  |
|    hid.enc.4.block.mlp_channels |    1.051M              |    0.537G  |
|   hid.enc.5.block               |   1.184M               |   0.572G   |
|    hid.enc.5.block.norm1        |    0.512K              |    0.655M  |
|    hid.enc.5.block.mlp_tokens   |    0.132M              |    33.554M |
|    hid.enc.5.block.norm2        |    0.512K              |    0.655M  |
|    hid.enc.5.block.mlp_channels |    1.051M              |    0.537G  |
|   hid.enc.6.block               |   1.184M               |   0.572G   |
|    hid.enc.6.block.norm1        |    0.512K              |    0.655M  |
|    hid.enc.6.block.mlp_tokens   |    0.132M              |    33.554M |
|    hid.enc.6.block.norm2        |    0.512K              |    0.655M  |
|    hid.enc.6.block.mlp_channels |    1.051M              |    0.537G  |
|   hid.enc.7                     |   1.282M               |   0.622G   |
|    hid.enc.7.block              |    1.184M              |    0.572G  |
|    hid.enc.7.reduction          |    98.688K             |    50.332M |
--------------------------------------------------------------------------------
1725938095508 lion error 
  | Name      | Type        | Params | Mode 
--------------------------------------------------
0 | model     | SimVP_Model | 11.1 M | train
1 | criterion | MSELoss     | 0      | train
--------------------------------------------------
11.1 M    Trainable params
0         Non-trainable params
11.1 M    Total params
44.401    Total estimated model params size (MB)
169       Modules in train mode
0         Modules in eval mode
